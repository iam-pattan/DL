{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU_LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNitUejI/IBzEtSuu4uLz7w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iam-pattan/DL/blob/master/GRU_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIK38C6SSJnR"
      },
      "source": [
        "# !wget 'https://www.gutenberg.org/files/236/236-0.txt'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLdApoF-SaGW"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, GRU\n",
        "from keras.optimizers import RMSprop\n",
        "import numpy as np\n",
        "import random\n",
        "import sys"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rSbHgdfSaLn",
        "outputId": "c930de82-ad6c-489b-d4cd-3fde793f81cb"
      },
      "source": [
        "#LOAD TEXT\n",
        "#Save notepad as UTF-8 (select from dropdown during saving)\n",
        "filename = \"/content/236-0.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()\n",
        "print(raw_text[0:1000])\n",
        "# "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿the project gutenberg ebook of the jungle book, by rudyard kipling\n",
            "\n",
            "this ebook is for the use of anyone anywhere at no cost and with\n",
            "almost no restrictions whatsoever.  you may copy it, give it away or\n",
            "re-use it under the terms of the project gutenberg license included\n",
            "with this ebook or online at www.gutenberg.org\n",
            "\n",
            "\n",
            "title: the jungle book\n",
            "\n",
            "author: rudyard kipling\n",
            "\n",
            "release date: january 16, 2006 [ebook #236]\n",
            "last updated: october 6, 2016\n",
            "\n",
            "language: english\n",
            "\n",
            "character set encoding: utf-8\n",
            "\n",
            "*** start of this project gutenberg ebook the jungle book ***\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "produced by an anonymous volunteer and david widger\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the jungle book\n",
            "\n",
            "by rudyard kipling\n",
            "\n",
            "\n",
            "\n",
            "contents\n",
            "\n",
            "     mowgli’s brothers\n",
            "     hunting-song of the seeonee pack\n",
            "     kaa’s hunting\n",
            "     road-song of the bandar-log\n",
            "     “tiger! tiger!”\n",
            "      mowgli’s song\n",
            "     the white seal\n",
            "     lukannon\n",
            "     “rikki-tikki-tavi”\n",
            "      darzee’s chant\n",
            "     toomai of the elephants\n",
            "     shiv and the grasshopper\n",
            "     her majesty’s servants\n",
            "     parade so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFbrbvpjSaPv"
      },
      "source": [
        "#CLEAN TEXT\n",
        "#Remove numbers\n",
        "raw_text = ''.join(c for c in raw_text if not c.isdigit())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kod8PL10SaTH"
      },
      "source": [
        "#How many total characters do we have in our training text?\n",
        "chars = sorted(list(set(raw_text))) #List of every character"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQeuv6RcSaX7"
      },
      "source": [
        "#Character sequences must be encoded as integers. \n",
        "#Each unique character will be assigned an integer value. \n",
        "#Create a dictionary of characters mapped to integer values\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMU2bkUISabS",
        "outputId": "c55f63ec-8ca7-4380-e79c-c49a7782d6bd"
      },
      "source": [
        "#Do the reverse so we can print our predictions in characters and not integers\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# summarize the data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters in the text; corpus length: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters in the text; corpus length:  292870\n",
            "Total Vocab:  51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOGWp2w2Saet",
        "outputId": "82b5e10f-da3a-424f-e12f-dbd27d009fc5"
      },
      "source": [
        "#Now that we have characters we can create input/output sequences for training\n",
        "#Remember that for LSTM input and output can be sequences... hence the term seq2seq\n",
        "\n",
        "seq_length = 60  #Length of each input sequence\n",
        "step = 10   #Instead of moving 1 letter at a time, try skipping a few. \n",
        "sentences = []    # X values (Sentences)\n",
        "next_chars = []   # Y values. The character that follows the sentence defined as X\n",
        "for i in range(0, n_chars - seq_length, step):  #step=1 means each sentence is offset just by a single letter\n",
        "    sentences.append(raw_text[i: i + seq_length])  #Sequence in\n",
        "    next_chars.append(raw_text[i + seq_length])  #Sequence out\n",
        "n_patterns = len(sentences)    \n",
        "print('Number of sequences:', n_patterns)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 29281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WzRuMLGSwVl",
        "outputId": "bf7ed187-6c7f-4b1c-a105-57326a0cfd60"
      },
      "source": [
        "#Just like time series, X is the sequence / sentence and y is the next value\n",
        "#that comes after the sentence... \n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "x = np.zeros((len(sentences), seq_length, n_vocab), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), n_vocab), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_to_int[char]] = 1\n",
        "    y[i, char_to_int[next_chars[i]]] = 1\n",
        "    \n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "\n",
        "print(y[0:10])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(29281, 60, 51)\n",
            "(29281, 51)\n",
            "[[False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False  True False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False  True False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False  True False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False]\n",
            " [False  True False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False  True False False False\n",
            "  False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "   True False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False  True False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False  True False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False]\n",
            " [False  True False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False  True False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6v5INOsSwPr",
        "outputId": "44293ece-a828-4be6-d346-dcce3c198e92"
      },
      "source": [
        "#Basic model with one LSTM\n",
        "# build the model: a single LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(GRU(128, input_shape=(seq_length, n_vocab)))\n",
        "model.add(Dense(n_vocab, activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, 128)               69504     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 51)                6579      \n",
            "=================================================================\n",
            "Total params: 76,083\n",
            "Trainable params: 76,083\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifxl8ok4SwJ7"
      },
      "source": [
        "# define the checkpoint\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath=\"saved_weights/saved_weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-J7NtQZSwB2",
        "outputId": "f844795d-4b0b-4764-ffe8-2c5492935aea"
      },
      "source": [
        "# Fit the model\n",
        "\n",
        "history = model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=10,   \n",
        "          callbacks=callbacks_list)\n",
        "\n",
        "model.save('my_saved_weights_jungle_book_50epochs.h5')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "229/229 [==============================] - 27s 118ms/step - loss: 1.7422\n",
            "\n",
            "Epoch 00001: loss improved from 1.94501 to 1.74221, saving model to saved_weights/saved_weights-01-1.7422.hdf5\n",
            "Epoch 2/10\n",
            "229/229 [==============================] - 27s 118ms/step - loss: 1.6189\n",
            "\n",
            "Epoch 00002: loss improved from 1.74221 to 1.61886, saving model to saved_weights/saved_weights-02-1.6189.hdf5\n",
            "Epoch 3/10\n",
            "229/229 [==============================] - 27s 118ms/step - loss: 1.5252\n",
            "\n",
            "Epoch 00003: loss improved from 1.61886 to 1.52516, saving model to saved_weights/saved_weights-03-1.5252.hdf5\n",
            "Epoch 4/10\n",
            "229/229 [==============================] - 27s 118ms/step - loss: 1.4505\n",
            "\n",
            "Epoch 00004: loss improved from 1.52516 to 1.45051, saving model to saved_weights/saved_weights-04-1.4505.hdf5\n",
            "Epoch 5/10\n",
            "229/229 [==============================] - 27s 118ms/step - loss: 1.3933\n",
            "\n",
            "Epoch 00005: loss improved from 1.45051 to 1.39330, saving model to saved_weights/saved_weights-05-1.3933.hdf5\n",
            "Epoch 6/10\n",
            "229/229 [==============================] - 27s 118ms/step - loss: 1.3545\n",
            "\n",
            "Epoch 00006: loss improved from 1.39330 to 1.35447, saving model to saved_weights/saved_weights-06-1.3545.hdf5\n",
            "Epoch 7/10\n",
            "229/229 [==============================] - 27s 118ms/step - loss: 1.3233\n",
            "\n",
            "Epoch 00007: loss improved from 1.35447 to 1.32332, saving model to saved_weights/saved_weights-07-1.3233.hdf5\n",
            "Epoch 8/10\n",
            "229/229 [==============================] - 27s 118ms/step - loss: 1.3085\n",
            "\n",
            "Epoch 00008: loss improved from 1.32332 to 1.30855, saving model to saved_weights/saved_weights-08-1.3085.hdf5\n",
            "Epoch 9/10\n",
            "229/229 [==============================] - 27s 118ms/step - loss: 1.3005\n",
            "\n",
            "Epoch 00009: loss improved from 1.30855 to 1.30055, saving model to saved_weights/saved_weights-09-1.3005.hdf5\n",
            "Epoch 10/10\n",
            "229/229 [==============================] - 27s 118ms/step - loss: 1.2920\n",
            "\n",
            "Epoch 00010: loss improved from 1.30055 to 1.29202, saving model to saved_weights/saved_weights-10-1.2920.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsH8LgrHSaAL"
      },
      "source": [
        "# Deeper model woth 2 LSTM\n",
        "#To stack LSTM layers, we need to change the configuration of the prior \n",
        "#LSTM layer to output a 3D array as input for the subsequent layer.\n",
        "#We can do this by setting the return_sequences argument on the layer to True \n",
        "#(defaults to False). This will return one output for each input time step and provide a 3D array.\n",
        "#Below is the same example as above with return_sequences=True.\n",
        "\n",
        "#model = Sequential()\n",
        "#model.add(LSTM(128, input_shape=(seq_length, n_vocab), return_sequences=True))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(LSTM(128))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(Dense(n_vocab, activation='softmax'))\n",
        "\n",
        "#optimizer = RMSprop(lr=0.01)\n",
        "#model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8qS7dxhbSv7I",
        "outputId": "41c1ecef-699b-42b6-9972-e6e3a604c5ca"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8ddnkskewpKwJEETtoAJkJC48itFe1u1Upeq11rX1lax1gVtXdprpb3dr/VaqrZqXW/d2lpxrbVWEa2CBghL2JcASViSICQBkpDM9/dHBgQNEEgmZybzfj4eeXBy5pyZdwbIe75nNeccIiISvXxeBxAREW+pCEREopyKQEQkyqkIRESinIpARCTKqQhERKKcikCinpn93cyu6O5ljzDDZDOr7O7nFemMWK8DiBwNM2vc79skoBloC35/jXPuqc4+l3PuzFAsKxIpVAQSkZxzKXunzawC+JZz7s1PL2dmsc651p7MJhJptGlIepW9m1jM7DYz2ww8Zmb9zOwVM6sxs4+D09n7rTPLzL4VnL7SzN4zs7uDy64zszOPctlcM5ttZg1m9qaZ3W9mf+rkzzEm+FrbzazczM7e77Evm9nS4PNWmdn3gvPTgz/bdjPbZmbvmpn+j8th6R+J9EaDgf7AscDVtP87fyz4/THAbuC+Q6x/IrACSAd+DTxiZnYUyz4NfAgMAKYDl3UmvJn5gZeBN4CBwPXAU2aWF1zkEdo3f6UCBcBbwfm3AJVABjAI+AGga8jIYakIpDcKAHc555qdc7udc3XOueedc7uccw3Az4DPH2L99c65h51zbcATwBDaf7F2elkzOwY4HviRc67FOfce8FIn858EpAC/DK77FvAKcHHw8T3AcWbWxzn3sXNu/n7zhwDHOuf2OOfedbqYmHSCikB6oxrnXNPeb8wsycweNLP1ZlYPzAb6mlnMQdbfvHfCObcrOJlyhMtmAtv2mwewsZP5M4GNzrnAfvPWA1nB6fOBLwPrzewdMzs5OP9/gNXAG2a21sxu7+TrSZRTEUhv9OlPwbcAecCJzrk+wKTg/INt7ukOm4D+Zpa037yhnVy3Ghj6qe37xwBVAM65j5xz59C+2Wgm8Ofg/Abn3C3OuWHA2cDNZvaFLv4cEgVUBBINUmnfL7DdzPoDd4X6BZ1z64FSYLqZxQU/tX+lk6vPBXYBt5qZ38wmB9d9Nvhcl5hZmnNuD1BP+6YwzGyKmY0I7qPYQfvhtIGOX0LkEyoCiQb3AolALTAHeL2HXvcS4GSgDvgp8Bzt5zscknOuhfZf/GfSnvkB4HLn3PLgIpcBFcHNXFODrwMwEngTaAQ+AB5wzr3dbT+N9FqmfUkiPcPMngOWO+dCPiIRORIaEYiEiJkdb2bDzcxnZmcA59C+TV8krOjMYpHQGQz8jfbzCCqBa51zC7yNJPJZ2jQkIhLltGlIRCTKRdymofT0dJeTk+N1DBGRiDJv3rxa51xGR49FXBHk5ORQWlrqdQwRkYhiZusP9pg2DYmIRDkVgYhIlFMRiIhEuYjbRyAi4WvPnj1UVlbS1NR0+IUlJBISEsjOzsbv93d6HRWBiHSbyspKUlNTycnJ4eD38pFQcc5RV1dHZWUlubm5nV5Pm4ZEpNs0NTUxYMAAlYBHzIwBAwYc8YhMRSAi3Uol4K2jef+jpgiamjawatVNBAJ7vI4iIhJWoqYIGhvLqKr6LZWV/+t1FBEJkbq6OgoLCyksLGTw4MFkZWXt+76lpeWQ65aWlnLDDTcc9jVOOeWUbsk6a9YspkyZ0i3P1VVRs7M4Pf1s0tPPo6JiOhkZF5KY2PkdKSISGQYMGEBZWRkA06dPJyUlhe9973v7Hm9tbSU2tuNfeyUlJZSUlBz2Nd5///3uCRtGomZEADBixAzMYli16rvoqqsi0eHKK69k6tSpnHjiidx66618+OGHnHzyyRQVFXHKKaewYsUK4MBP6NOnT+eb3/wmkydPZtiwYcyYMWPf86WkpOxbfvLkyVxwwQWMHj2aSy65ZN/vlddee43Ro0dTXFzMDTfccNhP/tu2bePcc89l3LhxnHTSSSxatAiAd955Z9+IpqioiIaGBjZt2sSkSZMoLCykoKCAd999t8vvUdSMCAASErLJzf0pq1ffRE3NXxk48EKvI4n0WqtW3URjY1m3PmdKSiEjR957xOtVVlby/vvvExMTQ319Pe+++y6xsbG8+eab/OAHP+D555//zDrLly/n7bffpqGhgby8PK699trPHJu/YMECysvLyczMZOLEifz73/+mpKSEa665htmzZ5Obm8vFF1982Hx33XUXRUVFzJw5k7feeovLL7+csrIy7r77bu6//34mTpxIY2MjCQkJPPTQQ5x++un88Ic/pK2tjV27dh3x+/FpUTUiAMjK+i4pKcWsXn0Dra07vI4jIj3gwgsvJCYmBoAdO3Zw4YUXUlBQwLRp0ygvL+9wnbPOOov4+HjS09MZOHAgW7Zs+cwyJ5xwAtnZ2fh8PgoLC6moqGD58uUMGzZs33H8nSmC9957j8suuwyA0047jbq6Ourr65k4cSI333wzM2bMYPv27cTGxnL88cfz2GOPMX36dBYvXkxqaurRvi37RNWIAMAshry8B5k37wTWrv0Bo0bd73UkkV7paD65h0pycvK+6TvvvJNTTz2VF154gYqKCiZPntzhOvHx8fumY2JiaG1tPapluuL222/nrLPO4rXXXmPixIn84x//YNKkScyePZtXX32VK6+8kptvvpnLL7+8S68TdSMCgNTUYrKzb6C6+vfs2DHH6zgi0oN27NhBVlYWAI8//ni3P39eXh5r166loqICgOeee+6w63zuc5/jqaeeAtr3PaSnp9OnTx/WrFnD2LFjue222zj++ONZvnw569evZ9CgQXz729/mW9/6FvPnz+9y5qgsAoCcnJ8QH5/FypXX6NwCkShy6623cscdd1BUVNTtn+ABEhMTeeCBBzjjjDMoLi4mNTWVtLS0Q64zffp05s2bx7hx47j99tt54oknALj33nspKChg3Lhx+P1+zjzzTGbNmsX48eMpKiriueee48Ybb+xy5oi7Z3FJSYnrrhvT1NTMpLz8PIYN+zXHHPP9bnlOkWi2bNkyxowZ43UMzzU2NpKSkoJzjuuuu46RI0cybdq0Hnv9jv4ezGyec67D42OjdkQAkJFxLgMGnENFxXR2767wOo6I9BIPP/wwhYWF5Ofns2PHDq655hqvIx1SVBcBwMiRvwOMVauu07kFItItpk2bRllZGUuXLuWpp54iKSnJ60iHFPVFkJAwlNzcn7Jt22vU1Hz2WGIROTL6QOWto3n/o74IYO+5BRN0boFIFyUkJFBXV6cy8Mje+xEkJCQc0XpRdx5BR3y+WPLyHgqeW/BDRo26z+tIIhEpOzubyspKampqvI4StfbeoexIqAiCUlOLycq6nqqqGQwefBl9+pzodSSRiOP3+4/ozlgSHrRpaD+5uf9NXFwmK1ZcQyDQ/ccXi4iEo5AVgZk9amZbzWzJQR7/vpmVBb+WmFmbmfUPVZ7OiI1NZeTI37Fz50Kqqn7rZRQRkR4TyhHB48AZB3vQOfc/zrlC51whcAfwjnNuWwjzdEp6+rkMGHA269b9iKam9V7HEREJuZAVgXNuNtDZX+wXA8+EKsuRMLN95xasXKlzC0Sk9/N8H4GZJdE+cjjoQfxmdrWZlZpZaU8cjZCQcAy5uf/Ntm2vUlv7t5C/noiIlzwvAuArwL8PtVnIOfeQc67EOVeSkZHRI6Gysq4nJaWIVauu17kFItKrhUMRfI0w2Sy0P58vllGjHqSlZTPr1v2X13FERELG0yIwszTg88CLXuY4mD59jicr67tUVd1Pff2HXscREQmJUB4++gzwAZBnZpVmdpWZTTWzqfstdh7whnNuZ6hydFVu7k+JixsSvG+Bzi0Qkd4nZGcWO+cOe6NO59zjtB9mGrZiY/swcuTvKC8/n6qqGQwderPXkUREulU47CMIe+np5zFgwFdYt+5OnVsgIr2OiqAT2s8tuI/2+xZ8V+cWiEivoiLopPZzC35CXd0r1Na+4HUcEZFuoyI4AllZN5CSUhg8t6De6zgiIt1CRXAEPjm3YJPOLRCRXkNFcIT69DmBrKzrqKq6j/r6j7yOIyLSZSqCo6BzC0SkN1ERHIXY2DRGjpxBY+MCqqp+53UcEZEuUREcpfT0rzJgwJTguQUbvI4jInLUVARH6ZNzC5zOLRCRiKYi6IKEhGPJyfkxdXUvU1s70+s4IiJHRUXQRdnZN5KcPD54bkGD13FERI6YiqCLfD4/eXkP0tJSzbp1d3odR0TkiKkIukGfPieSmfkdqqp+R319qddxRESOiIqgmwwb9jPi4gbp3AIRiTgqgm4SG5vGiBEzaGycT1XVfV7HERHpNBVBN8rIOJ/+/b/MunX/RVPTRq/jiIh0ioqgG7WfW3A/EGDVquu9jiMi0ikqgm6WmJgTPLfgRWpqdG6BiIQ/FUEIZGffRHLyOFat+q7OLRCRsKciCAGfzx+8b0E1FRU/8jqOiMghqQhCJC3tJDIzr6WycgYNDfO8jiMiclAqghAaNuznxMUNZMWKq3VugYiELRVBCLWfW/BbGhvnU119v9dxREQ6pCIIsYyMC+nf/0ydWyAiYUtFEGJ7zy1wro3Vq2/wOo6IyGeoCHpAYmIuOTnTqa2dSW3ti17HERE5gIqgh2RnTyM5eazOLRCRsKMi6CF7zy1obq7SuQUiElZUBD0oLe1kMjOnUln5W2prX/E6jogIoCLoccOH301KShHLln2dnTvLvY4jIqIi6GkxMUkUFMzE50ti8eKz2bOnzutIIhLlVAQeSEgYSkHBCzQ3V1Je/p8EAnu8jiQiUUxF4JG0tJPJy3uI7dvfYs2am72OIyJRLNbrANFs8OAraGxcTGXlb0hOHktm5tVeRxKRKBSyEYGZPWpmW81sySGWmWxmZWZWbmbvhCpLOBs+/Ff0738Gq1Zdx/bts72OIyJRKJSbhh4HzjjYg2bWF3gAONs5lw9cGMIsYcsshjFjniEhYTjl5eeze3eF15FEJMqErAicc7OBbYdY5OvA35xzG4LLbw1VlnDn9/dl7NiXCAT2sGTJObS2NnodSUSiiJc7i0cB/cxslpnNM7PLD7agmV1tZqVmVlpTU9ODEXtOUtIo8vP/zM6dS1i+/HKcC3gdSUSihJdFEAsUA2cBpwN3mtmojhZ0zj3knCtxzpVkZGT0ZMYe1b//lxg+/DfU1r5ARcWPvY4jIlHCy6OGKoE659xOYKeZzQbGAys9zOS57Owb2blzEevX/4Tk5AIGDozKXSci0oO8HBG8CPw/M4s1syTgRGCZh3nCgpkxatTv6dPnFJYvv4KGhgVeRxKRXi6Uh48+A3wA5JlZpZldZWZTzWwqgHNuGfA6sAj4EPijc+6gh5pGE58vnoKCv+H3p7NkyTm0tGzxOpKI9GLmnPM6wxEpKSlxpaWlXsfoEQ0NC1iwYCIpKUUUFr6FzxfvdSQRiVBmNs85V9LRY7rERBhLTS1i9OgnqK9/n5UrryXSSltEIoOKIMwNHHghxx57J5s3P0Zl5W+9jiMivZCKIALk5EwnPf081qy5hW3b3vA6joj0MiqCCGDmY/ToJ0lOLmDp0ovYtSuqj7AVkW6mIogQsbEpFBS8iFls8IY2272OJCK9hIoggiQm5pCf/zxNTWtYtuxinGvzOpKI9AIqggjTt+8kRo58gG3bXmfNmtu8jiMivYBuTBOBMjO/zc6di6is/A0pKWMZPPgKryOJSATTiCBCDR9+D337nsaKFVezY8ccr+OISARTEUQon89Pfv6fiY8fypIl59LUVOl1JBGJUCqCCOb3Dwje0GYXS5acS1vbLq8jiUgEUhFEuOTk4xgz5mkaG+ezYsVVugyFiBwxFUEvkJ4+hWHDfsHWrc+yYcMvvI4jIhFGRw31EkOH3kpj42LWrfshycn5pKef43UkEYkQGhH0EmZGXt7DpKYez7Jll9LYuNjrSCISIVQEvUhMTCIFBS8QE5MavKFNrdeRRCQCqAh6mfj4LAoKZtLcXM3SpRcSCOzxOpKIhDkVQS/Up88JjB79CNu3z2L16hu9jiMiYU47i3upQYMuobFxMRs3/ork5LFkZV3rdSQRCVMaEfRiw4b9jP79z2L16hv4+ONZXscRkTClIujFzGI47rinSUwcSXn5BezevdbrSCIShlQEvVxsbB8KCl4CAixZcg6trQ1eRxKRMNOpIjCzZDPzBadHmdnZZuYPbTTpLklJI8jP/ws7dy5j2bJLcS7gdSQRCSOdHRHMBhLMLAt4A7gMeDxUoaT79ev3BUaMuJe6updYt+5HXscRkTDS2SIw59wu4KvAA865C4H80MWSUMjKuo4hQ77Nhg0/Y8uWZ72OIyJhotNFYGYnA5cArwbnxYQmkoSKmTFy5H2kpX2OFSu+QUPDPK8jiUgY6GwR3ATcAbzgnCs3s2HA26GLJaHi88WRn/88fv8gFi36Mo2NS7yOJCIe61QROOfecc6d7Zz7VXCnca1z7oYQZ5MQiYvLYPz4f2AWS1nZZBoaFngdSUQ81Nmjhp42sz5mlgwsAZaa2fdDG01CKSkpj6Ki2cTEJLNw4WnU18/1OpKIeKSzm4aOc87VA+cCfwdyaT9ySCJYYuJwiopmExvbn4ULv8j27e95HUlEPNDZIvAHzxs4F3jJObcH0D0Re4GEhGMpKppNXNwQFi06nY8/fsvrSCLSwzpbBA8CFUAyMNvMjgXqQxVKelZ8fBaFhe+QkJDL4sVnsW3bP7yOJCI9qLM7i2c457Kcc1927dYDp4Y4m/Sg+PjBFBbOIilpNIsXn01t7cteRxKRHtLZncVpZnaPmZUGv35D++hAepG4uHTGj3+LlJTxlJd/lZqa572OJCI9oLObhh4FGoD/DH7VA48dagUze9TMtppZhweqm9lkM9thZmXBL133IAz4/f0YP/5NUlNPpLz8IrZsedrrSCISYp29Mc1w59z5+33/YzMrO8w6jwP3AU8eYpl3nXNTOplBekhsbB/GjXudJUu+wrJllxIINDNkyDe8jiUiIdLZEcFuM/t/e78xs4nA7kOt4JybDWzrQjbxUGxsCmPHvkq/fl9kxYpvUlX1B68jiUiIdHZEMBV40szSgt9/DFzRDa9/spktBKqB7znnyrvhOaWbxMQkUVDwIkuXXsiqVdcSCDQxdOhNXscSkW7W2aOGFjrnxgPjgHHOuSLgtC6+9nzg2ODz/g6YebAFzezqvTuqa2pquviyciRiYhLIz3+e9PTzWbNmGhs2/MrrSCLSzY7oDmXOufrgGcYAN3flhYPP1Ricfo32k9bSD7LsQ865EudcSUZGRldeVo6CzxfHccc9y8CBX2ft2tupqPgxzul8QpHeorObhjpiXXlhMxsMbHHOOTM7gfZSquvKc0ro+HyxjBnzJD5fHBUV0wkEmsnN/RlmXfpnICJhoCtFcMiPhGb2DDAZSDezSuAuwA/gnPsDcAFwrZm10r7j+WtOHzPDmlkMeXmPYBbPhg2/IBBoYvjw36gMRCLcIYvAzBro+Be+AYmHWtc5d/FhHr+P9sNLJYKY+Rg16vf4fAlUVv4vgUATI0feR/CW1iISgQ5ZBM651J4KIpHDzBgx4n/x+eLZuPHXBALN5OU9hJluWicSibqyaUiimJkxbNgv8fkSWL/+JwQCzYwe/Tg+n/5JiUQa/a+Vo2Zm5Ob+GJ8vgXXrfoBzzYwZ8zQ+n9/raCJyBFQE0mXHHnsHPl8Ca9bcTCDQQn7+n/H54r2OJSKdpD180i2GDp3GyJH3U1f3EkuWnEtb2yGvQCIiYURFIN0mK+s75OX9kW3b/sHixVNoa9vpdSQR6QQVgXSrIUOuYvToJ9m+fRaLFp1Ba6tuZCcS7lQE0u0GD76U4457lvr6OSxc+CX27NnudSQROQQVgYTEwIEXkp//Vxob57Nw4RfYs0dXDxEJVyoCCZn09HMoKHiRXbuWUlZ2Ki0tW7yOJCIdUBFISA0YcCZjx77C7t1rKCubTHNztdeRRORTVAQScv36fYFx416nubmSBQsm0dS0wetIIrIfFYH0iL59P8e4cf9kz55ayso+z+7d67yOJCJBKgLpMWlpJ1FY+C9aW+spK5vErl0rvY4kIqgIpIelphZTWPg2gUAzZWWfZ+fOpV5HEol6KgLpcSkp4ygsfAcwyso+T0PDAq8jiUQ1FYF4Ijl5DIWF7+DzJbJgwSlUVz+k+yCLeERFIJ5JShpJcXEpaWmTWLnyGpYuvViXpBDxgIpAPBUXN5Bx4/5Obu4vqKn5K6WlE2homOd1LJGooiIQz5n5OPbY2ykqegfnmpk//2QqK2doU5FID1ERSNhIS5tISUkZ/fufzurVN1Je/lX27NnmdSyRXk9FIGHF7x9AQcFLDB9+D3V1r1JaWsSOHXO8jiXSq6kIJOyYGUOHTqOo6D3MYigr+xwbNvwPzgW8jibSK6kIJGz16XMCxcXzGTDgHNauvZXFi6fQ0lLjdSyRXkdFIGHN7+9Lfv5fGDnyfj7++F+Ulhayfftsr2OJ9CoqAgl7ZkZW1neYMGEuMTHJlJWdSkXFT3GuzetoIr2CikAiRmpqIcXF8xg48GtUVNzJwoWn09y82etYIhFPRSARJTY2lTFj/kRe3iPU179Pael4tm170+tYIhFNRSARx8wYMuSbFBd/hN+fzqJFX2Lt2v8iEGj1OppIRFIRSMRKTs6nuPgjBg/+Bhs2/IyFC0+lqanS61giEUdFIBEtJiaJ0aMfYfTo/6OhYQGlpYXU1b3qdSyRiKIikF5h8OBLKSmZT3x8NosXT2HNmu8TCLR4HUskIqgIpNdIShrFhAlzyMz8Dhs33s2CBZPYvbvC61giYU9FIL1KTEwCo0bdz3HH/YVdu5ZRWlpITc3fvI4lEtZUBNIrDRx4ASUlC0hKGkV5+fmsWnU9bW1NXscSCUshKwIze9TMtprZksMsd7yZtZrZBaHKItEpMXEYRUXvkZ09jaqq+1iw4BR27VrldSyRsBPKEcHjwBmHWsDMYoBfAW+EMIdEMZ8vjhEj7qGg4EWamiqYN28CW7Y843UskbASsiJwzs0GDndXkeuB54GtocohApCefjYlJWUkJ49j2bKvs2LF1bS17fI6lkhY8GwfgZllAecBv/cqg0SXhIRjKCycxTHH3MGmTQ8zf/6J7Ny5zOtYIp7zcmfxvcBtrhN3GzGzq82s1MxKa2p0PXo5ej6fn2HDfs64ca/T0rKFefNK2Lz5Ca9jiXjKyyIoAZ41swrgAuABMzu3owWdcw8550qccyUZGRk9mVF6qf79T6ekpIw+fU5k+fIrWbbsclpbd3gdS8QTnhWBcy7XOZfjnMsB/gp8xzk306s8En3i4zMZP/6f5ORMZ8uWPzFnTg4VFT+ltbXe62giPSqUh48+A3wA5JlZpZldZWZTzWxqqF5T5EiZxZCTcxfFxfNIS5tERcWdzJmTy/r1P6e1tcHreCI9wpxzXmc4IiUlJa60tNTrGNJLNTTMo6JiOnV1rxAbO4ChQ79HVtZ3iY1N8TqaSJeY2TznXElHj+nMYpH9pKYWM3bsy0yYMJc+fU5g3bo7mDs3lw0bfk1b206v44mEhIpApAN9+pzAuHGvUVT0ASkpxaxdextz5uSyYcPdOv9Aeh0VgcghpKWdxPjxr1NU9D4pKYWsXft95szJZePGe1QI0muoCEQ6IS3tZMaPf4OiovdITh7LmjW3MHfucDZuvJe2tt1exxPpEhWByBFIS5tIYeGbFBbOJilpDGvWTGPu3OFUVs7Q1U0lYqkIRI5C376fo7DwLQoLZ5GYOIrVq28MFsJ9KgSJOCoCkS7o2/fzFBXNYvz4t0hMHM7q1dczd+4IqqoeIBBo9jqeSKeoCES6Qb9+p1JY+A7jx79JQkIOq1Zdx9y5I6muflD3TpawpyIQ6SZmRr9+X6Co6F3GjfsH8fFZrFw5lblzR1Fd/TCBwB6vI4p0SEUg0s3MjP79v0RR0fuMHft34uIGsXLl1Xz44Sg2bXpEhSBhR0UgEiJmxoABZzBhwhzGjn0Vvz+dFSu+xYcfjmbTpscIBFq9jigCqAhEQq69EL7MhAkfUlDwMrGx/Vix4pt8+OFoNm9+QoUgnlMRiPQQMyM9fQrFxR9RUPAisbF9WL78Sj766Dg2b/4/FYJ4RkUg0sPaC+FsiovnkZ//Aj5fEsuXX85HH+WzZctT2ocgPU5FIOIRMyMj41xKSuaTn/88Pl88y5Zdypw5x7Bu3Z00Na33OqJECRWBiMfMfGRkfJWSkjIKCl4mJaWY9et/xpw5uSxaNIXa2pdxrs3rmNKLxXodQETamflIT59CevoUmprWs2nTH9m06RGWLDmb+PihDBnyLYYMuYr4+Cyvo0ovozuUiYSxQGAPdXUvU139IB9//AYQQ3r6V8jMnEq/fl/ETIN66ZxD3aFMIwKRMObz+cnI+CoZGV9l9+41VFc/zObNj1JbO5OEhFyGDLmaIUO+QVzcIK+jSgTTiEAkwgQCzdTWzqS6+g9s3z4LMz/p6eeRmTmVvn0nY2ZeR5QwpBGBSC/i88UzcOBFDBx4ETt3LmfTpofYvPlxamr+TGLiKDIzr2Hw4Cvw+wd4HVUihDYwikSw5OTRjBhxDyefXMXo0U/i96ezZs0tvP9+FsuWXcaOHf8m0kb90vM0IhDpBWJiEhk8+DIGD76MxsbFVFc/yJYt/8eWLX8iKSmfzMypDBp0KX5/X6+jShjSiECkl0lJGcuoUfdxyinV5OX9kZiYRFavvp4PPshk+fKrqK//UKMEOYB2FotEgYaGecFRwtMEAjtJSSkiM/MaBg78OrGxqV7Hkx5wqJ3FGhGIRIHU1GLy8h7ilFOqGTnyAZxrY+XKqXzwQSYrV15LQ0OZ1xHFQxoRiEQh5xz19XPZtOlBtm59lkCgidTUE4OjhIuIiUnyOqJ0s0ONCFQEIlFuz56P2bLlSaqrH2TXrmXExKQxcODXSEs7mZSUCSQljcbn83sdU7pIRSAih+WcY8eOd6mufpDa2pkEArsAMOu8hEEAAAjUSURBVIsnJWUsKSlF+32N06ghwuiEMhE5LDOjb99J9O07Cefa2LVrFY2N82lsXEBDwwJqap5n06aHg0v7SErK21cMqakTSEkpxO/v7+nPIEdHRSAin2EWQ3LyaJKTRzNo0NeB9hFDc/PGYDG0F8SOHbPZuvXpfevFxx9LamrRAaOH+PgsXfYizKkIRKRTzIyEhGNISDiG9PRz9s1vaamlsXHBvq+GhgXU1r4ItG929vsz9hs5tP+ZmDhCV04NIyoCEemSuLh0+vf/Iv37f3HfvNbWRnbuXEhDwycFUVl5D86134YzJiaF5OTxB4wekpPz8fnivPoxopqKQES6XWxsCmlpE0lLm7hvXiDQws6dS4PFMJ+GhgVs3vw4bW33AWDmJzm54IDRQ1JSPrGxadq0FGIqAhHpET5fHKmphaSmFgLfAMC5ALt3r963SamxcQF1dS+zefOj+62XRHx8FvHxWcTFZR7wZ3x8JnFxWcTHD8Hni/foJ4t8ISsCM3sUmAJsdc4VdPD4OcB/AwGgFbjJOfdeqPKISPgx85GUNIqkpFEMHHgRsHendBWNjQvYtWsFLS3VNDdX09JSRX39BzQ3V+Nc82eey+9PD5bCp8vik2m/P137JjoQyhHB48B9wJMHefxfwEvOOWdm44A/A6NDmEdEIkD7TulsEhKyga985nHnHK2t22hurqa5uYqWlqr9pqv3lUhLyxb27rD+5Ln9xMUN2W8ksf+o4pMCibbrL4WsCJxzs80s5xCPN+73bTKf/hsTEemAmeH3D8DvH0BKytiDLhcI7KGlZfO+ctg7qtg7vWtXOR9//E/a2uo/s25MTOpnRhXx8UOJj88Ofg0Nji56x74LT/cRmNl5wC+AgcBZh1juauBqgGOOOaZnwolIRPP5/CQkDCUhYeghl2ttbexwVLH3z+3b36GlpRrnWg9Yzyz+gIJISDiwKOLjsyNmU1RILzERHBG80tE+gk8tNwn4kXPuPw73nLrEhIj0NOcCtLRsobm5Mvi1sYPpqn2Hx+5lFrdfOWQfMKrYWxx+f0aPlEXYX2IiuBlpmJmlO+dqvc4jIrI/Mx/x8UOIjx8CHN/hMu1lsfWgRdG+o/svBymLrA7LYu90XNzAkJaFZ0VgZiOANcGdxROAeKDOqzwiIl3RXhaDiY8fDHT4wRvnAuzZU0NzcyVNTR2VxVyam5/HuZZPPbef+PgssrK+y9Cht3R79lAePvoMMBlIN7NK4C7AD+Cc+wNwPnC5me0BdgMXuUi7FKqIyBEw8xEXN4i4uEGkphZ3uEx7WdQeUBB7SyMubkhockXa717tIxAROXK6VaWIiByUikBEJMqpCEREopyKQEQkyqkIRESinIpARCTKqQhERKKcikBEJMpF3AllZlYDrPc6RxelA7qm0if0fhxI78cn9F4cqCvvx7HOuYyOHoi4IugNzKz0YGf4RSO9HwfS+/EJvRcHCtX7oU1DIiJRTkUgIhLlVATeeMjrAGFG78eB9H58Qu/FgULyfmgfgYhIlNOIQEQkyqkIRESinIqgB5nZUDN728yWmlm5md3odSavmVmMmS0ws1e8zuI1M+trZn81s+VmtszMTvY6k5fMbFrw/8kSM3vGzBK8ztSTzOxRM9tqZkv2m9ffzP5pZquCf/brjtdSEfSsVuAW59xxwEnAdWZ2nMeZvHYjsMzrEGHit8DrzrnRwHii+H0xsyzgBqDEOVcAxABf8zZVj3scOONT824H/uWcGwn8K/h9l6kIepBzbpNzbn5wuoH2/+hZ3qbyjpllA2cBf/Q6i9fMLA2YBDwC4Jxrcc5t9zaV52KBRDOLBZKAao/z9Cjn3Gxg26dmnwM8EZx+Aji3O15LReARM8sBioC53ibx1L3ArUDA6yBhIBeoAR4Lbir7o5klex3KK865KuBuYAOwCdjhnHvD21RhYZBzblNwejMwqDueVEXgATNLAZ4HbnLO1XudxwtmNgXY6pyb53WWMBELTAB+75wrAnbSTcP+SBTc9n0O7QWZCSSb2aXepgovrv3Y/245/l9F0MPMzE97CTzlnPub13k8NBE428wqgGeB08zsT95G8lQlUOmc2ztC/CvtxRCt/gNY55yrcc7tAf4GnOJxpnCwxcyGAAT/3NodT6oi6EFmZrRvA17mnLvH6zxecs7d4ZzLds7l0L4T8C3nXNR+4nPObQY2mllecNYXgKUeRvLaBuAkM0sK/r/5AlG883w/LwFXBKevAF7sjidVEfSsicBltH/6LQt+fdnrUBI2rgeeMrNFQCHwc4/zeCY4MvorMB9YTPvvqqi63ISZPQN8AOSZWaWZXQX8Eviima2ifdT0y255LV1iQkQkumlEICIS5VQEIiJRTkUgIhLlVAQiIlFORSAiEuVUBCJBZta232G9ZWbWbWf2mlnO/leRFAknsV4HEAkju51zhV6HEOlpGhGIHIaZVZjZr81ssZl9aGYjgvNzzOwtM1tkZv8ys2OC8weZ2QtmtjD4tffSCDFm9nDwGvtvmFlicPkbgveoWGRmz3r0Y0oUUxGIfCLxU5uGLtrvsR3OubHAfbRfNRXgd8ATzrlxwFPAjOD8GcA7zrnxtF8vqDw4fyRwv3MuH9gOnB+cfztQFHyeqaH64UQORmcWiwSZWaNzLqWD+RXAac65tcGLBm52zg0ws1pgiHNuT3D+JudcupnVANnOueb9niMH+GfwhiKY2W2A3zn3UzN7HWgEZgIznXONIf5RRQ6gEYFI57iDTB+J5v2m2/hkH91ZwP20jx4+Ct6IRaTHqAhEOuei/f78IDj9Pp/cPvES4N3g9L+Aa2HfPZnTDvakZuYDhjrn3gZuA9KAz4xKREJJnzxEPpFoZmX7ff+6c27vIaT9glcFbQYuDs67nvY7in2f9ruLfSM4/0bgoeDVIttoL4VNdCwG+FOwLAyYoVtUSk/TPgKRwwjuIyhxztV6nUUkFLRpSEQkymlEICIS5TQiEBGJcioCEZEopyIQEYlyKgIRkSinIhARiXL/H/rkm4Bn3/xsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzJCV-HISvzS"
      },
      "source": [
        "#Writing our own softmax function....\n",
        "\n",
        "def sample(preds):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds) #exp of log (x), isn't this same as x??\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1) \n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5coGh2mTatG",
        "outputId": "283b1a7d-bed5-426d-ae65-5cbb3fda57d8"
      },
      "source": [
        "#Prediction\n",
        "# load the network weights\n",
        "filename = \"my_saved_weights_jungle_book_50epochs.h5\"\n",
        "model.load_weights(filename)\n",
        "\n",
        "#Pick a random sentence from the text as seed.\n",
        "start_index = random.randint(0, n_chars - seq_length - 1)\n",
        "\n",
        "#Initiate generated text and keep adding new predictions and print them out\n",
        "generated = ''\n",
        "sentence = raw_text[start_index: start_index + seq_length]\n",
        "generated += sentence\n",
        "\n",
        "print('----- Seed for our text prediction: \"' + sentence + '\"')\n",
        "#sys.stdout.write(generated)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Seed for our text prediction: \" know, he has an extra joint in his\n",
            "foreflipper, and by wavi\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROPcnCmlTdVP",
        "outputId": "169eac02-34e0-4d20-beaa-9f5a67e8f366"
      },
      "source": [
        "for i in range(400):   # Number of characters including spaces\n",
        "    x_pred = np.zeros((1, seq_length, n_vocab))\n",
        "    for t, char in enumerate(sentence):\n",
        "        x_pred[0, t, char_to_int[char]] = 1.\n",
        "\n",
        "    preds = model.predict(x_pred, verbose=0)[0]\n",
        "    next_index = sample(preds)\n",
        "    next_char = int_to_char[next_index]\n",
        "\n",
        "    generated += next_char\n",
        "    sentence = sentence[1:] + next_char\n",
        "\n",
        "    sys.stdout.write(next_char)\n",
        "    sys.stdout.flush()\n",
        "print()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "st swit was the end wat he had the live\n",
            "roter in his out things his head dad nove he cank theisgot only gould\n",
            "balhes measty.  akels, wergetennersaid, whith my cries tickly\n",
            "belangul for you mowh have hust him benderocks. his is thein for he wacr hoous the withoruteed\n",
            "him comilat of shere, knowly their mery will chreest tow they with pritting\n",
            "\n",
            "projeingiosi, it me a weelding on their\n",
            "the elophants, s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}